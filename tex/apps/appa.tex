\chapter{Cholesky decomposed errors}
\label{appa}

In order to create $K$ random series which are correlated exactly like $K$ deterministic series we have in mind, we can multiply independent random variables with the Cholesky decomposed part of the deterministic series. To illustrate this, let $\Sigma$ be a correlation matrix of matrix $X$ consisting of variables $x_1, x_2, ..., x_K$. Obviously the matrix is symmetric and the diagonal consists of $1$s. Let $\Sigma = LL'$ be a Cholesky decomposition of this matrix. Now, let $\Omega$ be a vector of $K$ independent random variables $\epsilon_1, \epsilon_2, ..., \epsilon_K$ with variance $1$. Consequently, the variance-covariance matrix of $\Omega$ is an identity matrix. Then we claim that the product $L\Omega$ has the same correlation structure as $X$. The proof is below:

\begin{center}
  $cov(L\Omega) = E[(L\Omega)(L\Omega)'] = E[L\Omega\Omega'L']$,\\
  $cov(L\Omega) = L \cdot E[\Omega\Omega'] \cdot L' = L \cdot var(\Omega) \cdot L'$,\\
  $cov(L\Omega) = L\cdot I \cdot L' = LL' = \Sigma$
\end{center}

Now consider the correlation matrix:

\begin{center}
	$R = \begin{bmatrix}
					1 & \rho_{sh} & \rho_{sy} \\
					\rho_{hs} & 1 & \rho_{hy} \\
					\rho_{ys} & \rho_{yh} & 1
			\end{bmatrix}
	$
\end{center}

Basic algebra gives its Cholesky decomposition as:

\begin{center}
	$Q = \begin{bmatrix}
					1 & 0 & 0 \\
					\rho_{hs} & \sqrt{1-\rho^2_{hs}} & 0 \\
					\rho_{ys} & \frac{\rho_{yh} - \rho_{sh}\rho_{sy}}{\sqrt{1-\rho^2_{sh}}} & \sqrt{1-\rho^2_{ys}-(\frac{\rho_{yh} - \rho_{sh}\rho_{sy}}{\sqrt{1-\rho^2_{sh}}})^2}
			\end{bmatrix}
	$
\end{center}
